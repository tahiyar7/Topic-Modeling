{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1526618,"sourceType":"datasetVersion","datasetId":897156}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Workflow\n1. [Data Content](#1)\n2. [Import Library](#2)\n3. [Data Preprocessing](#3)\n4. [Data Visualization](#4)\n5. [Train Test Validation Split](#5)\n6. [Model Train](#6)\n7. [Results Visualization](#7)","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n# Data Content\n\n1. **Predict Review Rating**\n\n1. **Topic Modeling on Reviews**","metadata":{}},{"cell_type":"markdown","source":"<a id='2'></a>\n# Import Library","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport re\nimport string\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport emoji\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-27T22:17:53.953785Z","iopub.execute_input":"2024-05-27T22:17:53.954918Z","iopub.status.idle":"2024-05-27T22:17:56.654799Z","shell.execute_reply.started":"2024-05-27T22:17:53.954874Z","shell.execute_reply":"2024-05-27T22:17:56.653593Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id='3'></a>\n# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"# the dataset has been linked to the kaggle data can be found in the link below: \n\n/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv\n\n# Another Link is: \n\nhttps://blog.devgenius.io/nlp-topic-modeling-lda-latent-dirichlet-allocation-f87679750e34","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.237790Z","iopub.status.idle":"2024-05-27T22:15:47.238454Z","shell.execute_reply.started":"2024-05-27T22:15:47.238150Z","shell.execute_reply":"2024-05-27T22:15:47.238179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.239988Z","iopub.status.idle":"2024-05-27T22:15:47.240892Z","shell.execute_reply.started":"2024-05-27T22:15:47.240318Z","shell.execute_reply":"2024-05-27T22:15:47.240347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.242945Z","iopub.status.idle":"2024-05-27T22:15:47.243848Z","shell.execute_reply.started":"2024-05-27T22:15:47.243530Z","shell.execute_reply":"2024-05-27T22:15:47.243558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.245182Z","iopub.status.idle":"2024-05-27T22:15:47.246117Z","shell.execute_reply.started":"2024-05-27T22:15:47.245883Z","shell.execute_reply":"2024-05-27T22:15:47.245904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.247231Z","iopub.status.idle":"2024-05-27T22:15:47.248166Z","shell.execute_reply.started":"2024-05-27T22:15:47.247944Z","shell.execute_reply":"2024-05-27T22:15:47.247964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.249109Z","iopub.status.idle":"2024-05-27T22:15:47.249972Z","shell.execute_reply.started":"2024-05-27T22:15:47.249757Z","shell.execute_reply":"2024-05-27T22:15:47.249778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Rating.nunique()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.251095Z","iopub.status.idle":"2024-05-27T22:15:47.251916Z","shell.execute_reply.started":"2024-05-27T22:15:47.251703Z","shell.execute_reply":"2024-05-27T22:15:47.251723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encode(x):\n    if x == 1 or x == 2:\n        return 0\n    if x == 3:\n        return 1\n    if x == 5 or x == 4:\n        return 2\n    \ndef label2name(x):\n    if x == 0:\n        return \"Negative\"\n    if x == 1:\n        return \"Neutral\"\n    if x == 2:\n        return \"Positive\"","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.253095Z","iopub.status.idle":"2024-05-27T22:15:47.253951Z","shell.execute_reply.started":"2024-05-27T22:15:47.253732Z","shell.execute_reply":"2024-05-27T22:15:47.253753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Rating.values","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.255125Z","iopub.status.idle":"2024-05-27T22:15:47.256249Z","shell.execute_reply.started":"2024-05-27T22:15:47.255997Z","shell.execute_reply":"2024-05-27T22:15:47.256036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"label\"] = df[\"Rating\"].apply(lambda x: label_encode(x))\ndf[\"label_name\"] = df[\"label\"].apply(lambda x: label2name(x))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.257290Z","iopub.status.idle":"2024-05-27T22:15:47.258471Z","shell.execute_reply.started":"2024-05-27T22:15:47.258203Z","shell.execute_reply":"2024-05-27T22:15:47.258228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    text=text.lower()\n    text=re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    text = re.sub(r'\\d+', '', text)\n    text=emoji.demojize(text)\n    stop_words=set(stopwords.words(\"english\"))\n    \n    text = text.split()\n    text=(word for word in text if word not in stop_words)\n    \n    lemmatizer = WordNetLemmatizer()\n    lemmatized_words=[lemmatizer.lemmatize(word) for word in text]\n    \n    clean_words=\" \".join(lemmatized_words)\n    \n    \n    return clean_words\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.259625Z","iopub.status.idle":"2024-05-27T22:15:47.260126Z","shell.execute_reply.started":"2024-05-27T22:15:47.259908Z","shell.execute_reply":"2024-05-27T22:15:47.259927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"lemmatize_text\"]=df.Review.apply(lambda x: clean_text(x))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.261331Z","iopub.status.idle":"2024-05-27T22:15:47.262243Z","shell.execute_reply.started":"2024-05-27T22:15:47.262002Z","shell.execute_reply":"2024-05-27T22:15:47.262036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"text_lenght\"]=df[\"Review\"].agg(len)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.263458Z","iopub.status.idle":"2024-05-27T22:15:47.264285Z","shell.execute_reply.started":"2024-05-27T22:15:47.264081Z","shell.execute_reply":"2024-05-27T22:15:47.264101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n# Data Visualization","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nmost_word=\" \".join(df[\"Review\"].values).split()\nword_counts=Counter(most_word)\nword_counts.most_common()\nmost_common_words_list = [{'word': word, 'count': count} for word, count in word_counts.items()]\n\nmost_words_df=pd.DataFrame(data=most_common_words_list,columns=[\"word\",\"count\"])\nmost_words_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.265400Z","iopub.status.idle":"2024-05-27T22:15:47.266240Z","shell.execute_reply.started":"2024-05-27T22:15:47.266038Z","shell.execute_reply":"2024-05-27T22:15:47.266059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"most_words_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.267336Z","iopub.status.idle":"2024-05-27T22:15:47.268128Z","shell.execute_reply.started":"2024-05-27T22:15:47.267913Z","shell.execute_reply":"2024-05-27T22:15:47.267934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(15,15))\nplt.subplot(2,1,1)\nsns.barplot(data=most_words_df[:20].sort_values(by=\"count\",ascending=False) ,y=\"word\",x=\"count\",palette=\"viridis\")\n\n\nlabels=most_words_df[:8].sort_values(by=\"count\",ascending=False)[\"word\"].values\nsizes=most_words_df[:8].sort_values(by=\"count\",ascending=False)[\"count\"].values\nexplode = (0.1, 0, 0, 0,0,0,0,0) \ncolors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue',\"Cyan\",\"red\",\"orange\",\"Brown\"]\n\nplt.figure(figsize=(15,15))\nplt.subplot(2,1,2)\n\nplt.pie(sizes,explode=explode,labels=labels,colors=colors,autopct='%1.1f%%', shadow=True,textprops={'fontsize': 10},labeldistance=0.85, startangle=0)\nplt.title(\"most used words\")\nplt.gca().add_artist(plt.Circle((0,0),0.70,fc='white'))\n\nplt.gcf().set_facecolor('#f0f0f0')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.269242Z","iopub.status.idle":"2024-05-27T22:15:47.269968Z","shell.execute_reply.started":"2024-05-27T22:15:47.269627Z","shell.execute_reply":"2024-05-27T22:15:47.269647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\n\n\ntext=str(list(df[\"Review\"]))\nplt.rcParams['figure.figsize'] = (15, 15)\nwordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 121).generate(text)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.271516Z","iopub.status.idle":"2024-05-27T22:15:47.272257Z","shell.execute_reply.started":"2024-05-27T22:15:47.272058Z","shell.execute_reply":"2024-05-27T22:15:47.272078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='5'></a>\n# Train Test Validation Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_text,val_text,train_label,val_label=train_test_split(df['lemmatize_text'], df['label'], test_size=0.15, random_state=42)\n\ntrain_text,test_text,train_label,test_label=train_test_split(train_text, train_label, test_size=0.1, random_state=42)\n\nprint(\"train_text shape: \",train_text.shape)\nprint(\"val_text shape:\",val_text.shape)\nprint(\"test_text shape: \",test_text.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.273362Z","iopub.status.idle":"2024-05-27T22:15:47.274169Z","shell.execute_reply.started":"2024-05-27T22:15:47.273956Z","shell.execute_reply":"2024-05-27T22:15:47.273976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndef bert_tokenize(text):\n    tokenized= tokenizer(text.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n    return tokenized\n\ntrain_tokenized=bert_tokenize(train_text)\nval_tokenized=bert_tokenize(val_text)\ntest_tokenized=bert_tokenize(test_text)\n\ntrain_label= torch.tensor(train_label.tolist())\nval_label= torch.tensor(val_label.tolist())\ntest_label= torch.tensor(test_label.tolist())\n\ntrain_dataset= torch.utils.data.TensorDataset(train_tokenized[\"input_ids\"],train_tokenized[\"attention_mask\"],train_label)\nval_dataset= torch.utils.data.TensorDataset(val_tokenized[\"input_ids\"],val_tokenized[\"attention_mask\"],val_label)\ntest_dataset= torch.utils.data.TensorDataset(test_tokenized[\"input_ids\"],test_tokenized[\"attention_mask\"],test_label)\n\nbatch_size = 32\ntrain_dataloader= torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader= torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\nval_dataloader= torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.275271Z","iopub.status.idle":"2024-05-27T22:15:47.276070Z","shell.execute_reply.started":"2024-05-27T22:15:47.275857Z","shell.execute_reply":"2024-05-27T22:15:47.275876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='6'></a>\n# Model Train","metadata":{}},{"cell_type":"code","source":"def train(model,train_loader,optimizer,criteron):\n    model.train()\n    train_loss=0\n    correct=0\n    total=0\n    \n    \n    \n    for batch in train_loader:\n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)  \n        labels = batch[2].to(device) \n        \n        #input_ids = batch[0]\n        #attention_mask = batch[1]\n        #labels = batch[2]\n       \n        \n        optimizer.zero_grad()\n        outputs=model(input_ids, attention_mask=attention_mask, labels=labels)\n        logits = outputs.logits\n        loss = criterion(logits, labels)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        \n        train_loss+=loss.item()\n        _, predicted = logits.max(1)\n        total+=labels.size(0)\n        correct+=predicted.eq(labels).sum().item()\n        \n    train_accuracy=100*correct/total\n    train_loss/=len(train_loader)\n    return train_loss,train_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.277205Z","iopub.status.idle":"2024-05-27T22:15:47.277987Z","shell.execute_reply.started":"2024-05-27T22:15:47.277790Z","shell.execute_reply":"2024-05-27T22:15:47.277809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model,valid_loader,criterion):\n    model.eval()\n    val_loss=0\n    correct=0\n    total=0\n    \n    with torch.no_grad():\n        for batch in valid_loader:\n            input_ids = batch[0].to(device)\n            attention_mask = batch[1].to(device)  \n            labels = batch[2].to(device)\n            \n            #input_ids = batch[0]\n            #attention_mask = batch[1]\n            #labels = batch[2]\n       \n            \n            outputs=model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            loss = criterion(logits, labels)\n            \n            \n            val_loss+=loss.item()\n            _, predicted = logits.max(1)\n            total+=labels.size(0)\n            correct+=predicted.eq(labels).sum().item()\n            \n        val_accuracy = 100.0 * correct / total\n        val_loss /= len(valid_loader)\n    return val_loss, val_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.279081Z","iopub.status.idle":"2024-05-27T22:15:47.279867Z","shell.execute_reply.started":"2024-05-27T22:15:47.279668Z","shell.execute_reply":"2024-05-27T22:15:47.279688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\nimport torch.optim as optim\nfrom torch.nn.parallel import DataParallel\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3) \nmodel =DataParallel(model)\nmodel = model.to(device)\n\noptimizer= optim.Adam(model.parameters(),lr=2e-5)\ncriterion=torch.nn.CrossEntropyLoss()\nepochs=5","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.280931Z","iopub.status.idle":"2024-05-27T22:15:47.281854Z","shell.execute_reply.started":"2024-05-27T22:15:47.281640Z","shell.execute_reply":"2024-05-27T22:15:47.281661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_accuracy=[]\nvalidation_accuracy=[]\ntrain_losses=[]\nvalidation_losses=[]\n\nfor epoch in range(epochs):\n    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n    val_loss, val_acc = validate(model, val_dataloader, criterion)\n    \n    train_accuracy.append(train_acc)\n    validation_accuracy.append(val_acc)\n    train_losses.append(train_loss)\n    validation_losses.append(val_loss)\n\n    \n    print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f} Train Accuracy: {train_acc:.2f}%, Validation Accuracy: {val_acc:.2f}%\")\n\ntorch.save(model.state_dict(), \"bert_model.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.283345Z","iopub.status.idle":"2024-05-27T22:15:47.283792Z","shell.execute_reply.started":"2024-05-27T22:15:47.283581Z","shell.execute_reply":"2024-05-27T22:15:47.283601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = '/kaggle/working/modelsave/'  \nos.makedirs(file_path, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.286217Z","iopub.status.idle":"2024-05-27T22:15:47.286967Z","shell.execute_reply.started":"2024-05-27T22:15:47.286725Z","shell.execute_reply":"2024-05-27T22:15:47.286748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save1 = model.module\nsave1.save_pretrained(\"/kaggle/working/modelsave/\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.288831Z","iopub.status.idle":"2024-05-27T22:15:47.289650Z","shell.execute_reply.started":"2024-05-27T22:15:47.289383Z","shell.execute_reply":"2024-05-27T22:15:47.289417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='7'></a>\n# Results Visualization","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax1 = plt.subplots()\n\n\nax2 = ax1.twinx()\n\nax2.plot(np.array(validation_accuracy),label = \"Validation Acc\",color=\"green\")\nax2.plot(np.array(train_accuracy),label = \"Train Acc\",color= \"red\")\nax1.legend()\nax2.legend()\nax1.set_xlabel('Epoch')\nax1.set_yticklabels([])\n\n\nfig.tight_layout()\nplt.title(\"Train vs Validation Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.290893Z","iopub.status.idle":"2024-05-27T22:15:47.291802Z","shell.execute_reply.started":"2024-05-27T22:15:47.291580Z","shell.execute_reply":"2024-05-27T22:15:47.291602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots()\n\n\nax2 = ax1.twinx()\n\nax2.plot(np.array(validation_losses),label = \"Validation Loss\",color=\"green\")\nax2.plot(np.array(train_losses),label = \"Train Loss\",color= \"red\")\nax1.legend()\nax2.legend()\nax1.set_xlabel('Epoch')\nax1.set_yticklabels([])\nfig.tight_layout()\nplt.title(\"Train vs Validation Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.293369Z","iopub.status.idle":"2024-05-27T22:15:47.294545Z","shell.execute_reply.started":"2024-05-27T22:15:47.294303Z","shell.execute_reply":"2024-05-27T22:15:47.294326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/working/bert_model.pth\"))\n\npredictions=[]\nactual_labels=[]\n\nmodel.eval()\n\nwith torch.no_grad():\n    for batch in test_dataloader:        \n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)\n        labels = batch[2].to(device)\n        \n        #input_ids = batch[0]\n        #attention_mask = batch[1]\n        #labels = batch[2]\n       \n        \n        outputs=model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        \n        _, predicted = logits.max(1)\n        \n        predictions.extend(predicted.cpu().numpy())\n        actual_labels.extend(labels.cpu().numpy())\n        \nresults_df=pd.DataFrame({\"Actual\":actual_labels,\"Predicted\":predictions})\nresults_df","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.295888Z","iopub.status.idle":"2024-05-27T22:15:47.296377Z","shell.execute_reply.started":"2024-05-27T22:15:47.296165Z","shell.execute_reply":"2024-05-27T22:15:47.296186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ntrue_labels=results_df[\"Actual\"]\npredicted_labels=results_df[\"Predicted\"]\n\naccuracy=accuracy_score(true_labels,predicted_labels)\n\ncorrect_predictions = (true_labels == predicted_labels).sum()\nprint(f\"Total number of correct predictions: {correct_predictions}\")\nprint(f\"Accuracy Score: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.297798Z","iopub.status.idle":"2024-05-27T22:15:47.298622Z","shell.execute_reply.started":"2024-05-27T22:15:47.298403Z","shell.execute_reply":"2024-05-27T22:15:47.298425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ntrue_labels=results_df[\"Actual\"]\npredicted_labels=results_df[\"Predicted\"]\n\nconfusionMatrix = confusion_matrix(true_labels, predicted_labels)\nsns.heatmap(confusionMatrix, annot=True, cmap='viridis', fmt='g')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.300497Z","iopub.status.idle":"2024-05-27T22:15:47.301002Z","shell.execute_reply.started":"2024-05-27T22:15:47.300774Z","shell.execute_reply":"2024-05-27T22:15:47.300795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertConfig\nconfig = BertConfig.from_json_file('/kaggle/working/modelsave/config.json')\n\nmodel =  BertForSequenceClassification.from_pretrained('/kaggle/working/modelsave/', config=config)\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.303160Z","iopub.status.idle":"2024-05-27T22:15:47.303604Z","shell.execute_reply.started":"2024-05-27T22:15:47.303393Z","shell.execute_reply":"2024-05-27T22:15:47.303413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.305887Z","iopub.status.idle":"2024-05-27T22:15:47.306395Z","shell.execute_reply.started":"2024-05-27T22:15:47.306189Z","shell.execute_reply":"2024-05-27T22:15:47.306210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.lemmatize_text[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.307410Z","iopub.status.idle":"2024-05-27T22:15:47.307803Z","shell.execute_reply.started":"2024-05-27T22:15:47.307614Z","shell.execute_reply":"2024-05-27T22:15:47.307632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label_name'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.310040Z","iopub.status.idle":"2024-05-27T22:15:47.310945Z","shell.execute_reply.started":"2024-05-27T22:15:47.310721Z","shell.execute_reply":"2024-05-27T22:15:47.310743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment","metadata":{}},{"cell_type":"code","source":"df['label_name'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.312431Z","iopub.status.idle":"2024-05-27T22:15:47.313506Z","shell.execute_reply.started":"2024-05-27T22:15:47.313242Z","shell.execute_reply":"2024-05-27T22:15:47.313275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.label.values[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.315148Z","iopub.status.idle":"2024-05-27T22:15:47.315583Z","shell.execute_reply.started":"2024-05-27T22:15:47.315378Z","shell.execute_reply":"2024-05-27T22:15:47.315398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#text = 'nice hotel expensive parking got good deal stay hotel anniversary arrived late evening took advice previous review valet parking check quick easy little disappointed nonexistent view room room clean nice size bed comfortable woke stiff neck high pillow soundproof like heard music room night morning loud bang door opening closing hear people talking hallway maybe noisy neighbor aveda bath product nice goldfish stay nice touch taken advantage staying longer location great walking distance shopping overall nice experience pay parking night'\ntext=df.lemmatize_text.values[:30]\ndef bert_tokenize(text):\n    tokenized= tokenizer(text.tolist() ,padding=True, truncation=True, return_tensors=\"pt\")\n    return tokenized\n\ntext = bert_tokenize(text)\npredictions=list()\nfor i in range(30):\n    with torch.no_grad():\n        model_output = model(**text[i:i+1]) \n        predicted = torch.softmax(model_output.logits, dim=1).tolist()[0]\n        predictions.append(predicted)\n\nlabel_names=[\"Negative\",\"Neutral\",\"Positive\"]\nfor i, predicted in enumerate(predictions):\n    print(\"text {}: {}\\n\".format(i,df.lemmatize_text.iloc[i]))\n    for j,label_name in enumerate(label_names):\n        \n        print(f\"{label_name}: {predicted[j] * 100:.2f}%\")\n        \n    print(\"\\nactual label_name:{}, actual rating score:{}\\n\".format(df.label_name.iloc[i],df.Rating.iloc[i]))\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T22:15:47.317479Z","iopub.status.idle":"2024-05-27T22:15:47.318230Z","shell.execute_reply.started":"2024-05-27T22:15:47.317978Z","shell.execute_reply":"2024-05-27T22:15:47.318002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# If you like it, you can support it by voting. :))","metadata":{}}]}